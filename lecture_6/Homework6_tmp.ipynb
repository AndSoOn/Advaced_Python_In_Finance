{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Set 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 \n",
    "\n",
    "D. Bindel and J. Goodman: Principles of Scientific Computing, Chapter 6, Exercise 7.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "#### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that $\\phi(t)$ is minimized when $\\phi^{'}(t) = 0$  \n",
    "i.e.  \n",
    "$$\\begin{array}{l}\n",
    "\\phi^{'}(t) &= \\nabla V(\\bar{x} + tp_{k})^{T} p_{k}\\\\\n",
    "&= p_{k+1}^{T}p_{k}\\\\\n",
    "&= 0\n",
    "\\end{array}$$\n",
    "Which shows $p_{k+1}$ and $p_{k}$ are orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\nabla V(\\bar{x}) = (\\lambda_{1}x_{1}, \\lambda_{2}x_{2})^{T}$ and $p_{k+1}$ and $p_{k}$ are orthogonal.  \n",
    "So if $p_{k}$ is in the direction of $(-1, -1)^{T}$  \n",
    "We will have:\n",
    "$$\\begin{array}{l}\n",
    "p_{k}^{T}p_{k+1} &= (-1, -1)^{T} (\\lambda_{1}x_{1}^{(k+1)}, \\lambda_{2}x_{2}^{(k+1)})\\\\\n",
    "&= 0\n",
    "\\end{array}$$\n",
    "Which means $ \\lambda_{1}x_{1}^{(k+1)} = - \\lambda_{2}x_{2}^{(k+1)})$  \n",
    "Therefore $p_{k+1} = c(-1, 1)^{T}$, where $c$ is a constant factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $p_{k} = \\nabla V(\\bar{x}) = (\\lambda_{1}x_{1}, \\lambda_{2}x_{2})^{T}$.  \n",
    "\n",
    "So if $p_{k}$ is in the direction of $(-1, -1)^{T}$, we will have:  \n",
    "$(\\lambda_{1}x_{1}, \\lambda_{2}x_{2})^{T} = c(-1, -1)^{T}$\n",
    "\n",
    "Which means $(x_{1}, x_{2}) = r(\\lambda_{1}, \\lambda_{2})$, where $ r(\\lambda_{1}, \\lambda_{2}) = c(\\frac{-1}{\\lambda_{1}}, \\frac{-1}{\\lambda_{2}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without loss of generality, we start from $x^{(0)} = (\\lambda_{2}, \\lambda_{1})^{T}$\n",
    "\n",
    "The gradient at $x^{(k)}$ is $(\\lambda_{1}x_{1}, \\lambda_{2}x_{2})^{T}$, so we get  \n",
    "\n",
    "$x^{(k)} + t\\nabla V(x^{(k)}) = \\left[\\begin{array} \\\\ (1+t\\lambda_{1})x_{1}^{(k)} \\\\ (1+t\\lambda_{2})x_{2}^{(k)}  \\end{array} \\right]$\n",
    "\n",
    "and\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V(x^{(k+1)}) = \\frac{1}{2}(\\lambda_{1}(1+t\\lambda_{1})^{2}(x_{1}^{(k)})^{2} + \\lambda_{2}(1+t\\lambda_{2})^{2}(x_{2}^{(k)})^{2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "For the quadratic programming problem derived for portfolio optimization\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "\\\\\n",
    "\\min_{\\bf x} & &  \\frac{1}{2} \\lambda\\; {\\bf x}^T \\Sigma {\\bf x} - \\mu^T {\\bf x} \n",
    "\\\\\n",
    "s.t. & & \\Sigma x_i = 1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is the risk-aversion coefficient, $\\mu$ is the expected asset return vector and $\\Sigma$ is the covariance matrix.  Derive the dual problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4dd8b47b877d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "set(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
